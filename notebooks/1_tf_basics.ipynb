{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5btyi6OeQ0V"
      },
      "source": [
        "![prova](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/TensorFlow_logo.svg/1200px-TensorFlow_logo.svg.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DIpawh-DeQ0f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZWIy0vLUeQ0m",
        "outputId": "b6cc8a5d-f460-4e15-80b5-8e7d284155a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjPlD5HgeQ0p"
      },
      "source": [
        "# Tensor Manipulation Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbJY_oJCeQ0r"
      },
      "source": [
        "### Tensor Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0ABSx10eQ0t"
      },
      "source": [
        "A 0-dimensional tensor is a __scalar__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PF3Gd0BeQ0v",
        "outputId": "8999d35a-9e07-422a-959b-2cd613f7a7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of the tensor = 0\n",
            "Number of dimensions = 0\n",
            "Tensor's shape = ()\n"
          ]
        }
      ],
      "source": [
        "scalar = tf.constant(0)\n",
        "print(f\"Value of the tensor = {scalar}\")\n",
        "print(f\"Number of dimensions = {len(scalar.shape)}\")\n",
        "print(f\"Tensor's shape = {scalar.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bi0T4YneQ0y"
      },
      "source": [
        "A 1-dimensional tensor is a __vector__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVISRYz_eQ0z",
        "outputId": "1799e520-f69f-4a4f-f3df-9997fa16fc6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of the tensor = [1 2 3]\n",
            "Number of dimensions = 1\n",
            "Tensor's shape = (3,)\n"
          ]
        }
      ],
      "source": [
        "vector = tf.constant([1, 2, 3])\n",
        "print(f\"Value of the tensor = {vector}\")\n",
        "print(f\"Number of dimensions = {len(vector.shape)}\")\n",
        "print(f\"Tensor's shape = {vector.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17w6WIOUeQ03"
      },
      "source": [
        "A 2-dimensional tensor is a __matrix__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w85BebdeQ04",
        "outputId": "0917278e-d31e-452a-bd3d-6d7b7ce338dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of the tensor = \n",
            " [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "Number of dimensions = 2\n",
            "Tensor's shape = (3, 3)\n"
          ]
        }
      ],
      "source": [
        "matrix = tf.constant(\n",
        "    [[1, 2, 3],\n",
        "     [4, 5, 6],\n",
        "     [7, 8, 9]]\n",
        ")\n",
        "print(f\"Value of the tensor = \\n {matrix}\")\n",
        "print(f\"Number of dimensions = {len(matrix.shape)}\")\n",
        "print(f\"Tensor's shape = {matrix.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY7d9a5CeQ05"
      },
      "source": [
        "We can generalize tensors to __n dimensions__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol-uLpPjeQ06",
        "outputId": "101c4dfe-2774-45ef-9071-cc205e1b2398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of the tensor = \n",
            " [[[-0.9179252  -0.6546959  -0.48851842]\n",
            "  [ 0.18864796 -0.09569727  0.63443893]\n",
            "  [ 1.0678033   0.2696759   0.6021515 ]]\n",
            "\n",
            " [[ 0.6944288  -2.5329533   1.0535876 ]\n",
            "  [-1.9319733   0.00712121 -0.73306704]\n",
            "  [-0.7982862  -0.6908891  -1.1475171 ]]\n",
            "\n",
            " [[ 0.88749534 -1.1834891   0.5968224 ]\n",
            "  [-0.11839477  0.11850872 -0.65293765]\n",
            "  [ 0.01463446 -2.3556614  -1.3417951 ]]]\n",
            "Number of dimensions = 3\n",
            "Tensor's shape = (3, 3, 3)\n"
          ]
        }
      ],
      "source": [
        "n = 3\n",
        "tensor = tf.random.normal(tuple(3 for _ in range(n)))\n",
        "print(f\"Value of the tensor = \\n {tensor}\")\n",
        "print(f\"Number of dimensions = {len(tensor.shape)}\")\n",
        "print(f\"Tensor's shape = {tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzMwFgSSeQ08"
      },
      "source": [
        "Each tensor is characterized also by a __data type__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16mU1o2GeQ08",
        "outputId": "48a7548e-1ba5-4591-a20c-e38e63740173"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ADVA4COeQ09"
      },
      "source": [
        "Which can be cast to others (with the clear consequences on the numerical representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MccI56MreQ0-",
        "outputId": "ee377db4-28de-4587-c687-7441bab8ddf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  0  0]\n",
            "  [ 0  0  0]\n",
            "  [ 1  0  0]]\n",
            "\n",
            " [[ 0 -2  1]\n",
            "  [-1  0  0]\n",
            "  [ 0  0 -1]]\n",
            "\n",
            " [[ 0 -1  0]\n",
            "  [ 0  0  0]\n",
            "  [ 0 -2 -1]]], shape=(3, 3, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "int_tensor = tf.cast(tensor, dtype=tf.int32)\n",
        "print(int_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMVmAXPNeQ0_"
      },
      "source": [
        "### Tensor indexing e slicing\n",
        "\n",
        "Tensors can be __indexed__ (i.e., ``tensor[i, :, :]``) or __sliced__ (i.e., ``tensor[:i, ...]``)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8gTJ5HGeQ1A"
      },
      "source": [
        "Indexing a tensor reduces its dimensionality depending to the number of \"free\" dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKlsGX8SeQ1A",
        "outputId": "b1b56649-4866-410d-a9d7-2848efedce03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar = 0.18864795565605164\n",
            "Vector = [-0.48851842  1.0535876   0.5968224 ]\n",
            "Matrix = [[ 1.0678033   0.2696759   0.6021515 ]\n",
            " [-0.7982862  -0.6908891  -1.1475171 ]\n",
            " [ 0.01463446 -2.3556614  -1.3417951 ]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Scalar = {tensor[0, 1, 0]}\")\n",
        "print(f\"Vector = {tensor[:, 0, -1]}\") # : means all elements in that dimension\n",
        "print(f\"Matrix = {tensor[:, 2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Omitting a component/dimension is equivalent to considering all elements in that component/dimension"
      ],
      "metadata": {
        "id": "IvUI91UxgzDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor[:,2,:] == tensor[:,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP4x0qJwgpk1",
        "outputId": "76c33417-64c2-439d-9d36-bf240eadf6f6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=bool, numpy=\n",
              "array([[ True,  True,  True],\n",
              "       [ True,  True,  True],\n",
              "       [ True,  True,  True]])>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5UtPyRseQ1B"
      },
      "source": [
        "Slicing reduces the size of the sliced dimension. With this approach, only contiguous slices can be taken. To get scattered slices, use [``tf.gather``](https://www.tensorflow.org/api_docs/python/tf/gather)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FQno_DcieQ1B",
        "outputId": "f2365d37-d145-42bd-d720-649833b1ce44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_slice = [[[ 0.6944288  -2.5329533   1.0535876 ]\n",
            "  [-1.9319733   0.00712121 -0.73306704]\n",
            "  [-0.7982862  -0.6908891  -1.1475171 ]]\n",
            "\n",
            " [[ 0.88749534 -1.1834891   0.5968224 ]\n",
            "  [-0.11839477  0.11850872 -0.65293765]\n",
            "  [ 0.01463446 -2.3556614  -1.3417951 ]]]\n",
            "Shape of tensor_slice = (2, 3, 3)\n",
            "Number of dimensions = 3\n"
          ]
        }
      ],
      "source": [
        "tensor_slice = tensor[1:]\n",
        "print(f\"tensor_slice = {tensor_slice}\")\n",
        "print(f\"Shape of tensor_slice = {tensor_slice.shape}\")\n",
        "print(f\"Number of dimensions = {len(tensor_slice.shape)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SRVlLD2jeQ1C",
        "outputId": "beaaa82a-09e8-4739-bd18-308be1bb7088",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_slice = [[[ 1.0535876 ]\n",
            "  [-0.73306704]\n",
            "  [-1.1475171 ]]\n",
            "\n",
            " [[ 0.5968224 ]\n",
            "  [-0.65293765]\n",
            "  [-1.3417951 ]]]\n",
            "Shape of tensor_slice = (2, 3, 1)\n",
            "Number of dimensions = 3\n"
          ]
        }
      ],
      "source": [
        "tensor_slice = tensor[1:, :, -1:]\n",
        "print(f\"tensor_slice = {tensor_slice}\")\n",
        "print(f\"Shape of tensor_slice = {tensor_slice.shape}\")\n",
        "print(f\"Number of dimensions = {len(tensor_slice.shape)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzmwnLrYeQ1D"
      },
      "source": [
        "Indexing and slicing can be also mixed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uPuwT7OjeQ1D",
        "outputId": "956157cb-f07f-45dc-9db8-c200b4132368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_slice = [[ 1.0535876  -0.73306704 -1.1475171 ]\n",
            " [ 0.5968224  -0.65293765 -1.3417951 ]]\n",
            "Shape of tensor_slice = (2, 3)\n",
            "Number of dimensions = 2\n"
          ]
        }
      ],
      "source": [
        "tensor_slice = tensor[1:, :, 2]\n",
        "print(f\"tensor_slice = {tensor_slice}\")\n",
        "print(f\"Shape of tensor_slice = {tensor_slice.shape}\")\n",
        "print(f\"Number of dimensions = {len(tensor_slice.shape)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2vnGPxReQ1E"
      },
      "source": [
        "### Concat and stack\n",
        "\n",
        "- ``tf.concat``: concatenates n tensors on the `axis` dimension. All the dimensions of the input tensors, except for the `axis` dimension, must match.\n",
        "- ``tf.stack``: stacks n tensors on the `axis` dimension, which is added for the resulting tensor. All the dimensions of the input tensors must match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "eySr1TmfeQ1F",
        "outputId": "629105a5-07c7-4d07-eacf-872f38d3a102",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape = (2, 9, 4)\n"
          ]
        }
      ],
      "source": [
        "tensor_1 = tf.random.normal((2, 3, 4))\n",
        "tensor_2 = tf.random.uniform((2, 6, 4))\n",
        "concat_tensor = tf.concat([tensor_1, tensor_2], axis=1)\n",
        "print(f\"Shape = {concat_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1Y-VjlHaeQ1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df23ddd-fe45-4918-d700-5841617b8cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape = (2, 2, 3, 4)\n"
          ]
        }
      ],
      "source": [
        "tensor_2 = tf.random.uniform((2, 3, 4))\n",
        "stacked_tensor = tf.stack([tensor_1, tensor_2], axis=1)\n",
        "print(f\"Shape = {stacked_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dB4wrCweQ1G"
      },
      "source": [
        "### Your turn!\n",
        "\n",
        "1. Create a tensor with random numbers of shape (2, 5, 3);\n",
        "2. Get the last element on dimension 1;\n",
        "3. Put it at the beginning of dimension 1.\n",
        "\n",
        "_Note_: use the placeholders on the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YcRvk1UDeQ1G"
      },
      "outputs": [],
      "source": [
        "init_tensor = tf.random.uniform((2,5,3))\n",
        "last = init_tensor[:,-1,:]\n",
        "\n",
        "# Mode 1:\n",
        "#final_tensor = tf.stack([last, *[init_tensor[:,i,:] for i in range(0,4)]], axis=1)\n",
        "\n",
        "# Mode 2:\n",
        "#last = init_tensor[:,-1:]\n",
        "#final_tensor = tf.concat([last, init_tensor[:,0:-1,:]], axis=1)\n",
        "\n",
        "# Mode 3:\n",
        "# This works in numpy but in tf. Preposterous!\n",
        "#final_tensor = init_tensor[:,[4,0,1,2,3],:]\n",
        "\n",
        "# Mode 4:\n",
        "# The TensorFlow way of doing Mode 3. Cringe.\n",
        "final_tensor = tf.gather(init_tensor, indices=[4,0,1,2,3], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HRJPjGbkeQ1H",
        "outputId": "4cb18ef6-d5d9-4910-bd0a-94d6ceb6e450",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good job!\n"
          ]
        }
      ],
      "source": [
        "if final_tensor.shape == (2, 5, 3):\n",
        "    if tf.reduce_all(final_tensor[:, 0] == init_tensor[:, -1]):\n",
        "        print(\"Good job!\")\n",
        "    else:\n",
        "        print(\"Mh, correct dimensions but wrong values\")\n",
        "else:\n",
        "    print(f\"Wrong, dimensions are {init_tensor.shape} and {final_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps35PeIyeQ1H"
      },
      "source": [
        "# Tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZVgPFExeQ1I"
      },
      "source": [
        "``+, *, /, -`` are overloaded to support tensor operations. All the operations are element-wise, support broadcasting for the non-matching dimensions (i.e., (2, 1, 2) + (2, 3, 2) --> (2, 3, 2))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8tEcygHteQ1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1701de7e-d159-4b14-e4da-bd4bc5f7e7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[-0.9645222  -1.5352426   2.276219  ]\n",
            "  [ 0.68187964  0.5960277  -0.14831781]\n",
            "  [-1.1113595  -1.1751916  -1.0571522 ]]\n",
            "\n",
            " [[ 0.07063098  1.0881443  -0.22375423]\n",
            "  [-0.3450527   2.3107924  -0.23893796]\n",
            "  [ 1.0406713  -1.8252059   0.14320555]]\n",
            "\n",
            " [[ 1.2746583   0.10838494  0.6578258 ]\n",
            "  [ 0.6828306   1.0316279  -0.8437864 ]\n",
            "  [ 1.2121109  -0.39021495  0.1060509 ]]], shape=(3, 3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "tensor = tf.random.normal((3, 3, 3))\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9uyQNrDfeQ1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def8c734-515d-4ffc-b375-c30579293ff8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 3), dtype=float32, numpy=\n",
              "array([[[ 0.03547782, -0.53524256,  3.276219  ],\n",
              "        [ 1.6818796 ,  1.5960276 ,  0.8516822 ],\n",
              "        [-0.11135948, -0.17519164, -0.05715215]],\n",
              "\n",
              "       [[ 1.070631  ,  2.0881443 ,  0.7762458 ],\n",
              "        [ 0.6549473 ,  3.3107924 ,  0.761062  ],\n",
              "        [ 2.0406713 , -0.8252059 ,  1.1432055 ]],\n",
              "\n",
              "       [[ 2.2746582 ,  1.108385  ,  1.6578258 ],\n",
              "        [ 1.6828306 ,  2.031628  ,  0.15621358],\n",
              "        [ 2.212111  ,  0.6097851 ,  1.1060508 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "tensor + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qdd32BfSeQ1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9eb02c-063d-4e24-999a-b05971164c80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 3), dtype=float32, numpy=\n",
              "array([[[-4.822611  , -7.676213  , 11.381094  ],\n",
              "        [ 3.409398  ,  2.9801383 , -0.74158907],\n",
              "        [-5.5567975 , -5.8759584 , -5.285761  ]],\n",
              "\n",
              "       [[ 0.35315487,  5.4407215 , -1.1187711 ],\n",
              "        [-1.7252635 , 11.553963  , -1.1946898 ],\n",
              "        [ 5.2033567 , -9.12603   ,  0.71602774]],\n",
              "\n",
              "       [[ 6.3732915 ,  0.5419247 ,  3.2891293 ],\n",
              "        [ 3.4141529 ,  5.158139  , -4.218932  ],\n",
              "        [ 6.0605545 , -1.9510747 ,  0.5302545 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "tensor * 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "1zxpDd5QeQ1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69cfe381-5460-4be6-c6fa-c7534a5ba313"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 3), dtype=float32, numpy=\n",
              "array([[[-0.4822611 , -0.7676213 ,  1.1381094 ],\n",
              "        [ 0.34093982,  0.29801384, -0.07415891],\n",
              "        [-0.55567974, -0.5875958 , -0.5285761 ]],\n",
              "\n",
              "       [[ 0.03531549,  0.54407215, -0.11187711],\n",
              "        [-0.17252634,  1.1553962 , -0.11946898],\n",
              "        [ 0.5203357 , -0.91260296,  0.07160278]],\n",
              "\n",
              "       [[ 0.63732916,  0.05419247,  0.3289129 ],\n",
              "        [ 0.3414153 ,  0.51581395, -0.4218932 ],\n",
              "        [ 0.60605544, -0.19510747,  0.05302545]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "tensor / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-onsQ8tOeQ1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f745279d-69e8-437d-fe95-cac2c1491faa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[ 0.34699446,  0.69687057],\n",
              "       [-1.3462895 , -2.6659923 ],\n",
              "       [ 0.45165616,  1.1073738 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "tensor_1 = tf.random.normal((3, 2))\n",
        "tensor_2 = tf.random.normal((3, 2))\n",
        "tensor_1 + tensor_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDagNbBTeQ1L"
      },
      "source": [
        "`@` defines the dot product between two tensors. The inner dimensions must match the criterion for the dot product."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 @ tf.transpose(tensor_2, [1, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCSHKo2qGvpE",
        "outputId": "a3940da4-0faf-4d71-b791-bc5af801f809"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[-1.16477   , -0.9116821 , -1.0140982 ],\n",
              "       [-0.56742156,  1.90447   , -0.30242676],\n",
              "       [-0.76875603, -1.3503723 , -0.73038566]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KUkIuRqyeQ1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6123230-9f45-464b-bcc5-ae4e7fd0a2e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 3, 3), dtype=float32, numpy=\n",
              "array([[[-2.4696503e+00, -1.3996162e+00, -2.9180944e-01],\n",
              "        [ 5.6832314e-01, -9.4959712e-01, -4.9681792e-01],\n",
              "        [ 2.0703151e+00,  1.4230438e+00,  3.5538095e-01]],\n",
              "\n",
              "       [[-1.6937010e+00, -9.0339643e-01, -1.7450755e+00],\n",
              "        [ 1.6518906e-01,  8.3146304e-02, -3.8972178e-01],\n",
              "        [ 1.2507921e-01,  7.3073566e-02,  8.4615302e-01]],\n",
              "\n",
              "       [[ 5.9910637e-01,  6.4479530e-02, -3.9262912e-01],\n",
              "        [-6.1814529e-01,  8.3518338e-01,  8.7786025e-01],\n",
              "        [-6.2821966e-01, -8.5573596e-01, -1.4921129e-03]],\n",
              "\n",
              "       [[ 1.2739542e+00,  3.2124364e-01,  9.4505757e-02],\n",
              "        [-2.8389397e+00, -1.2696511e+00,  1.5225432e+00],\n",
              "        [-6.9835320e+00, -2.5590999e+00,  1.9797835e+00]],\n",
              "\n",
              "       [[-9.9790543e-02, -7.3863149e-01, -2.2421086e+00],\n",
              "        [-1.2140174e+00, -1.1986370e+00, -5.2818823e+00],\n",
              "        [ 7.1887612e-01,  1.3783524e+00,  5.0160294e+00]],\n",
              "\n",
              "       [[ 1.1218979e-01, -1.3854502e-01,  1.9365045e-03],\n",
              "        [ 3.2046992e-01,  5.5299211e-01,  7.7082378e-01],\n",
              "        [ 5.8129835e-01,  9.3398929e-01,  1.3424703e+00]],\n",
              "\n",
              "       [[-9.7894818e-01, -2.8027627e+00, -3.3211780e+00],\n",
              "        [-1.0154091e+00,  2.5010166e+00, -1.9634275e+00],\n",
              "        [ 1.0333233e+00,  1.6016304e+00,  3.1339827e+00]],\n",
              "\n",
              "       [[-4.2315472e-02, -3.5752618e-01, -1.0799493e-01],\n",
              "        [ 7.0369534e-02,  6.8800402e-01,  1.2979007e-01],\n",
              "        [ 5.1680729e-02,  2.0293148e+00, -7.1691239e-01]],\n",
              "\n",
              "       [[-3.3072665e-02,  6.1662942e-01, -9.1953683e-01],\n",
              "        [ 1.0243006e+00, -2.5393087e-01, -4.2326176e-01],\n",
              "        [ 4.2872563e-02, -2.6006460e-01,  3.6486635e-01]],\n",
              "\n",
              "       [[ 7.3950744e-01,  4.1874319e-02,  8.5768938e-01],\n",
              "        [ 1.0303351e+00,  3.3160651e+00,  9.4029486e-01],\n",
              "        [ 1.1160362e+00,  8.1820554e-01,  1.2353626e+00]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "tensor_1 = tf.random.normal((10, 3, 2))\n",
        "tensor_2 = tf.random.normal((10, 3, 2))\n",
        "tensor_1 @ tf.transpose(tensor_2, [0, 2, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor operations are a bit **weird** (at least for me, Matlab user):"
      ],
      "metadata": {
        "id": "zId2aiRaCBCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = tf.constant([1,2,3])\n",
        "matrix = tf.constant(\n",
        "    [[1, 2, 3],\n",
        "     [4, 5, 6],\n",
        "     [7, 8, 9]]\n",
        ")\n",
        "\n",
        "print(f\"Matrix @ transpose(vector) = \\n {matrix @ tf.reshape(vector,[3,1])}\\n\")\n",
        "print(f\"Matrix * transpose(vector) = \\n {matrix * tf.reshape(vector,[3,1])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3IlQdd8B_-b",
        "outputId": "173a9483-5948-4147-e147-cb0c2e081a07"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix @ transpose(vector) = \n",
            " [[14]\n",
            " [32]\n",
            " [50]]\n",
            "\n",
            "Matrix * transpose(vector) = \n",
            " [[ 1  2  3]\n",
            " [ 8 10 12]\n",
            " [21 24 27]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But `vector` has to be explicitely reshaped to apply @"
      ],
      "metadata": {
        "id": "7N0pxGJcCFPn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv1osS9oeQ1M"
      },
      "source": [
        "# Learning with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0KyiQr5eQ1N"
      },
      "source": [
        "### Digit Classification with a Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "DLSCCEUOeQ1N"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "croNZFWweQ1O",
        "outputId": "fd7e1b13-a890-44c5-bcbc-cc747b22c81c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data(path='ds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_17WnWsZeQ1O",
        "outputId": "494f68cc-3555-4233-ccfd-4025a1ea4fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label is 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "print(f\"Label is {train_y[0]}\")\n",
        "Image.fromarray(train_x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7RHEaGLveQ1P",
        "outputId": "116781f3-3c38-4b51-860b-b6c6fbd1c2b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "train_x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLZKixxveQ1P"
      },
      "source": [
        "Images need to be flattened to be taken as input by a linear classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "M22CUIe3eQ1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5fbb6c9-529a-4e7f-c9e9-2c9d534bafc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "train_x = tf.reshape(train_x, [train_x.shape[0], -1])\n",
        "print(train_x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7apD5qReQ1Q"
      },
      "source": [
        "Need to __rescale__ the values to the interval [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "5nESA_JqeQ1Q"
      },
      "outputs": [],
      "source": [
        "train_x = train_x / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFfzYYFEeQ1R"
      },
      "source": [
        "Defining the linear model requires only a weight matrix and a bias vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "etoHGWhKeQ1S"
      },
      "outputs": [],
      "source": [
        "W, b = tf.Variable(tf.random.normal((784, 10))), tf.Variable(tf.zeros(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "kHeVjX9AeQ1S",
        "outputId": "5e513adf-e860-45bd-d86d-8ae93ad13206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
              "array([[0.10165986, 0.10580491, 0.10039227, ..., 0.10293652, 0.09841168,\n",
              "        0.0938332 ],\n",
              "       [0.10013852, 0.10519222, 0.10317238, ..., 0.10312901, 0.09519397,\n",
              "        0.09783196],\n",
              "       [0.10129441, 0.09951231, 0.10269225, ..., 0.09972475, 0.10235385,\n",
              "        0.09808753],\n",
              "       ...,\n",
              "       [0.0992156 , 0.10373273, 0.0979123 , ..., 0.10063779, 0.09995594,\n",
              "        0.09546796],\n",
              "       [0.09976178, 0.10024145, 0.10108333, ..., 0.10442971, 0.09961037,\n",
              "        0.09644014],\n",
              "       [0.10261587, 0.10242018, 0.10496174, ..., 0.10038301, 0.10104081,\n",
              "        0.0967429 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVbKeNqneQ1T"
      },
      "source": [
        "Now that we have our linear model, let's define the tools for the optimization, i.e., __the optimizer and the loss function__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "zNyx6DDFeQ1T"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-1)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9AZbQ43eQ1T"
      },
      "source": [
        "A training loop with TensorFlow is shaped as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "xcddmM8veQ1U",
        "outputId": "b5b8ff02-c2e8-424d-c407-bee486625761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: accuracy = 0.14551666666666666\n",
            "Epoch 20: accuracy = 0.14335\n",
            "Epoch 40: accuracy = 0.13351666666666667\n",
            "Epoch 60: accuracy = 0.1247\n",
            "Epoch 80: accuracy = 0.11966666666666667\n",
            "Epoch 100: accuracy = 0.117\n",
            "Epoch 120: accuracy = 0.116\n",
            "Epoch 140: accuracy = 0.11493333333333333\n",
            "Epoch 160: accuracy = 0.11426666666666667\n",
            "Epoch 180: accuracy = 0.11391666666666667\n",
            "Epoch 200: accuracy = 0.1137\n",
            "Epoch 220: accuracy = 0.11366666666666667\n",
            "Epoch 240: accuracy = 0.11361666666666667\n",
            "Epoch 260: accuracy = 0.11358333333333333\n",
            "Epoch 280: accuracy = 0.1135\n",
            "Epoch 300: accuracy = 0.11336666666666667\n",
            "Epoch 320: accuracy = 0.11336666666666667\n",
            "Epoch 340: accuracy = 0.11333333333333333\n",
            "Epoch 360: accuracy = 0.11335\n",
            "Epoch 380: accuracy = 0.11336666666666667\n",
            "Epoch 400: accuracy = 0.11335\n",
            "Epoch 420: accuracy = 0.11335\n",
            "Epoch 440: accuracy = 0.11333333333333333\n",
            "Epoch 460: accuracy = 0.11333333333333333\n",
            "Epoch 480: accuracy = 0.11331666666666666\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "epochs = 500\n",
        "\n",
        "for e in range(epochs):\n",
        "    # The GradientTape context records every operation applied to tensors\n",
        "    # inside the context. The tape can then be used to compute the gradient\n",
        "    # of a computation with respect to the tensors it has \"watched\".\n",
        "    with tf.GradientTape() as tape:\n",
        "        prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
        "        loss_value = loss_fn(train_y, prediction)\n",
        "\n",
        "    # We compute the gradient of the loss with respect to the parameters\n",
        "    # of the model\n",
        "    grads = tape.gradient(loss_value, [W, b])\n",
        "\n",
        "    # We apply the gradient to the parameters of the model\n",
        "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
        "\n",
        "    # We print the loss every 20 epochs\n",
        "    prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
        "    if e % 20 == 0:\n",
        "        print(f\"Epoch {e}: accuracy = {accuracy_score(train_y, tf.argmax(prediction, axis=-1))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VsTjlqoeQ1U"
      },
      "source": [
        "Of course, if we use Adam as optimization approach, the performance in the learning phase increases dramatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "VfR54S8YeQ1V",
        "outputId": "715412fb-9f03-4db8-b76c-746e697554d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 0: accuratezza = 0.2212\n",
            "Epoca 20: accuratezza = 0.7274\n",
            "Epoca 40: accuratezza = 0.7645833333333333\n",
            "Epoca 60: accuratezza = 0.7851\n",
            "Epoca 80: accuratezza = 0.80215\n",
            "Epoca 100: accuratezza = 0.8155666666666667\n",
            "Epoca 120: accuratezza = 0.8270333333333333\n",
            "Epoca 140: accuratezza = 0.8370166666666666\n",
            "Epoca 160: accuratezza = 0.8444833333333334\n",
            "Epoca 180: accuratezza = 0.8503333333333334\n",
            "Epoca 200: accuratezza = 0.8557666666666667\n",
            "Epoca 220: accuratezza = 0.8603166666666666\n",
            "Epoca 240: accuratezza = 0.8641666666666666\n",
            "Epoca 260: accuratezza = 0.8673333333333333\n",
            "Epoca 280: accuratezza = 0.8704666666666667\n",
            "Epoca 300: accuratezza = 0.8729333333333333\n",
            "Epoca 320: accuratezza = 0.8752\n",
            "Epoca 340: accuratezza = 0.8773833333333333\n",
            "Epoca 360: accuratezza = 0.8794833333333333\n",
            "Epoca 380: accuratezza = 0.88135\n",
            "Epoca 400: accuratezza = 0.8831666666666667\n",
            "Epoca 420: accuratezza = 0.8847\n",
            "Epoca 440: accuratezza = 0.8860833333333333\n",
            "Epoca 460: accuratezza = 0.88745\n",
            "Epoca 480: accuratezza = 0.8885666666666666\n"
          ]
        }
      ],
      "source": [
        "W, b = tf.Variable(tf.random.normal((784, 10))), tf.Variable(tf.zeros(10))\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "epochs = 500\n",
        "\n",
        "for e in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
        "        loss_value = loss_fn(train_y, prediction)\n",
        "\n",
        "    grads = tape.gradient(loss_value, [W, b])\n",
        "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
        "\n",
        "    if e % 20 == 0:\n",
        "        prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
        "        print(f\"Epoca {e}: accuratezza = {accuracy_score(train_y, tf.argmax(prediction, axis=-1))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWkeA4r8eQ1V"
      },
      "source": [
        "### Your turn!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPbEQjVQeQ1V"
      },
      "source": [
        "Try to implement your own training loop with a linear regression on the Boston Housing dataset.\n",
        "\n",
        "Notes:\n",
        "1. It is a regression problem, so you need to use a different loss function;\n",
        "2. MinMax Scaling may not be the most appropriate way to rescale the input features (maybe sklearn's StandardScaler?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "bjgMBgyjeQ1W"
      },
      "outputs": [],
      "source": [
        "(train_x, train_y), _ = tf.keras.datasets.boston_housing.load_data(\"./ds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ZKNfBvZFeQ1W",
        "outputId": "1b73a432-07f3-4ad9-822d-c2bed293f1da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 13), (404,))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "train_x.shape, train_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "DsxxQ3gneQ1X",
        "outputId": "88d64791-bbf6-400c-a5ea-a496b08ab303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13,), 15.2)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "train_x[0].shape, train_y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "f1VLQvZxeQ1X"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_x = scaler.fit_transform(train_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "34bHVXC9eQ1X"
      },
      "outputs": [],
      "source": [
        "hiddenUnits = 1\n",
        "W, b = tf.Variable(tf.random.normal((13,hiddenUnits))), tf.Variable(tf.zeros(hiddenUnits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "bBeDvH9xeQ1Y"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-1)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_x @ W + b).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ChYre2gWeAU",
        "outputId": "d419a148-7871-4f75-e643-46031841597d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([404, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "7V4kdCwVeQ1Y",
        "outputId": "cbfb1587-d826-44be-b32a-57cae2115df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ciao\n",
            "ciao\n",
            "ciao\n",
            "ciao\n",
            "ciao\n",
            "ciao\n",
            "ciao\n",
            "ciao\n",
            "ciao\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-d94190d5c121>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# We compute the gradient of the loss with respect to the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# We apply the gradient to the parameters of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_rank\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minput_rank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1597\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mreal_div\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   8087\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8088\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8089\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   8090\u001b[0m         _ctx, \"RealDiv\", name, x, y)\n\u001b[1;32m   8091\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "epochs = 420\n",
        "\n",
        "for e in range(epochs):\n",
        "    # The GradientTape context records every operation applied to tensors\n",
        "    # inside the context. The tape can then be used to compute the gradient\n",
        "    # of a computation with respect to the tensors it has \"watched\".\n",
        "    with tf.GradientTape() as tape:\n",
        "        prediction = train_x @ W + b\n",
        "        loss_value = loss_fn(train_y, prediction)\n",
        "\n",
        "    # We compute the gradient of the loss with respect to the parameters\n",
        "    # of the model\n",
        "    grads = tape.gradient(loss_value, [W, b])\n",
        "\n",
        "    # We apply the gradient to the parameters of the model\n",
        "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
        "\n",
        "    # We print the loss every 20 epochs\n",
        "    prediction = train_x @ W + b\n",
        "    if e % 20 == 0:\n",
        "        print('ciao')\n",
        "        #print(f\"Epoch {e}: mse = {mean_squared_error(train_y, prediction)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmSOtMW7eQ1Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tf_mela')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3917c018cfd92834e25e8ac39593c8ba50cba5d103d91e5ca7d5a867c45ae1af"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}